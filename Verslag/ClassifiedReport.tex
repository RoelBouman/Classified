
%%%%%%%%%%%%%%%%%%%%%%% file typeinst.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is the LaTeX source for the instructions to authors using
% the LaTeX document class 'llncs.cls' for contributions to
% the Lecture Notes in Computer Sciences series.
% http://www.springer.com/lncs       Springer Heidelberg 2006/05/04
%
% It may be used as a template for your own input - copy it
% to a new file with a new name and use it as the basis
% for your article.
%
% NB: the document class 'llncs' has its own and detailed documentation, see
% ftp://ftp.springer.de/data/pubftp/pub/tex/latex/llncs/latex2e/llncsdoc.pdf
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[runningheads,a4paper]{llncs}

\usepackage[utf8]{inputenc}

\usepackage{natbib}
\bibliographystyle{apalike}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage[T1]{fontenc} % Pour que les lettres accentuées soient reconnues

\usepackage{url}
\urldef{\mailsa}\path|{alfred.hofmann, ursula.barth, ingrid.haas, frank.holzwarth,|
\urldef{\mailsb}\path|anna.kramer, leonie.kunz, christine.reiss, nicole.sator,|
\urldef{\mailsc}\path|erika.siebert-cole, peter.strasser, lncs}@springer.com|    
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}

\mainmatter 

\title{Classified: TalkingData}

\titlerunning{Classified: TalkingData}

\author{Jordi Beernink, Thijs Werrij, Roel Bouman, Gerdriaan Mulder, Jeffrey Luppes}

\institute{Radboud University}

\authorrunning{Team Classified - TalkingData}

\toctitle{Abstract}
\tocauthor{{}}

\maketitle

\begin{abstract}
Lorem Ipsum todo lang leve het bier en dan wel lachouffe. Liefde is mooi, liefde is puur. Vrouwen zijn raar, en verschrikkelijk duur. 
\end{abstract}

\medskip

\begingroup
\let\clearpage\relax
\tableofcontents
\addcontentsline{toc}{section}{Introduction}
\endgroup

\medskip
\medskip

\section{Introduction}
This report details the work done on the TalkingData Competition data set by the Classified team. While the competition closed in September of 2016,  the data set remained public and open to submissions while the leaderboard was frozen.

In this report a number of approaches that were tried are discussed along with their results. Finally, some other ideas for follow-up work are discussed as well as individual contributions by team members. All of the code referenced in this report can be found in a Github repository linked to at the end of this report. 

\subsection{Data set}
The data set was collected from Kaggle and consisted of eight csv files totalling 1.2 GB. In order to generate a single data set these files were merged based on the device ID, which generated a data set of 4.2 GB. This data was fairly sparse, as many entries only had a few associated events, while others ranged in the thousands. This was true also for the phone brand types with some phones appearing only a few times while others had quite a massive share. 
\medskip

A short schema of the raw data is as follows:
\begin{itemize}
\item app\_events: \textit{event\_id, app\_id, is\_installed, is\_active}
\item app\_labels: \textit{app\_id, label\_id}
\item events: \textit{event\_id, device\_id, timestamp, coordinates}
\item gender\_age: \textit{device\_id, gender, age, group}
\item phone\_brand\_device\_model: \textit{device\_id, phone\_brand, device\_model}
\end{itemize}

\subsection{Problem Description}
\textit{"Nothing is more comforting than being greeted by your favorite drink just as you walk through the door of the corner café." -- TalkingData Competition Page } 
\smallskip
\newline
\noindent
The goal of the competition is to predict mobile behaviour based upon app usage, phone brand and location information. As an abstraction upon this, the goal is to accurately predict in which gender and age group the owner of a mobile device resides. The predictions are accepted as twelve categories: six age groups for each gender. 
\subsection{Evaluation}
Submissions are evaluated using the multi-class logarithmic loss algorithm. For each device the output is a row in a csv file with the device\_id followed by twelve probabilities between 0 and 1 corresponding to the prediction for each class.
\section{Approach}
<wat we gedaan hebben in vogelvlucht>
\subsection{Pre-Processing}
<wat de struggles waren bij pp>
\subsection{Feature Extraction}
<idem>
\subsection{Classifiers}
Een stukkie over NN, XGB, en RF? Jordi en ik XGB, Thijss NN en Roel even RF?
\section{Results}
<onzeker of dit voor of na de scores moet komen>
\subsection{Submission Scores}
<overzicht van de scores, beginnende met de baseline >
\section{Discussion}
<discussie resultaten>
\section{Future work}
A number of concepts were considered but not explored (fully) 


\section{Individual Contributions}
By alphanummeric ordering:
\begin{itemize}
\item Jordi Beernink: \textit{Project leader, Pre-processing, XGBoost implementation}
\item Roel Bouman: \textit{Classification Pipeline and RF implementation}
\item Jeffrey Luppes: \textit{XGBoost implementation, Report writing}
\item Gerdriaan Mulder: \textit{Pre-processing, installation on the lilo servers}
\item Thijs Werrij - \textit{Deep Learning}
\end{itemize}
\subsection{Github Repository}
All code accompanying this report may be retrieved from \url{https://github.com/RoelBouman/Classified/tree/first_competition} where it has been bundled as a release. The README on that page alsohas extensive material on how to run the code on the lilo.science.ru.nl servers where it has been prepared for a demo. 
\medskip
\bibliography{references}
\nocite{*} 

\end{document}
