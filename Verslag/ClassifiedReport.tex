
%%%%%%%%%%%%%%%%%%%%%%% file typeinst.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is the LaTeX source for the instructions to authors using
% the LaTeX document class 'llncs.cls' for contributions to
% the Lecture Notes in Computer Sciences series.
% http://www.springer.com/lncs       Springer Heidelberg 2006/05/04
%
% It may be used as a template for your own input - copy it
% to a new file with a new name and use it as the basis
% for your article.
%
% NB: the document class 'llncs' has its own and detailed documentation, see
% ftp://ftp.springer.de/data/pubftp/pub/tex/latex/llncs/latex2e/llncsdoc.pdf
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[runningheads,a4paper]{llncs}

\usepackage[utf8]{inputenc}

\usepackage{natbib}
\bibliographystyle{apalike}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage[T1]{fontenc} % Pour que les lettres accentuées soient reconnues

\usepackage{url}
\urldef{\mailsa}\path|{alfred.hofmann, ursula.barth, ingrid.haas, frank.holzwarth,|
\urldef{\mailsb}\path|anna.kramer, leonie.kunz, christine.reiss, nicole.sator,|
\urldef{\mailsc}\path|erika.siebert-cole, peter.strasser, lncs}@springer.com|    
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}

\mainmatter 

\title{Classified: TalkingData}

\titlerunning{Classified: TalkingData}

\author{Jordi Beernink, Thijs Werrij, Roel Bouman, Gerdriaan Mulder, Jeffrey Luppes}

\institute{Radboud University}

\authorrunning{Team Classified - TalkingData}

\toctitle{Abstract}
\tocauthor{{}}

\maketitle

\begin{abstract}
Todo as of 18/4: 
- Stukjes Jordi en Thijs zonder wij-vorm
- Stukje over RF
-
\end{abstract}

\medskip

\begingroup
\let\clearpage\relax
\tableofcontents
\addcontentsline{toc}{section}{Introduction}
\endgroup

\medskip
\medskip

\section{Introduction}
This report details the work done on the TalkingData Competition data set by the Classified team. While the competition closed in September of 2016,  the data set remained public and open to submissions but the leaderboard was frozen.

In this report a number of approaches that were tried are discussed along with their results. Finally, some other ideas for follow-up work are discussed as well as individual contributions by team members. All of the code referenced in this report can be found in a Github repository linked to at the end of this report. 

\subsection{Data set}
The data set was collected from Kaggle and consisted of eight csv files totalling 1.2 GB. In order to generate a single data set these files were merged based on the device ID, which generated a data set of 4.2 GB. This data was fairly sparse, as many entries only had a few associated events, while others ranged in the thousands. This was true also for the phone brand types with some phones appearing only a few times while others had quite a massive share. 
\medskip

A short schema of the raw data is as follows:
\begin{itemize}
\item app\_events: \textit{event\_id, app\_id, is\_installed, is\_active}
\item app\_labels: \textit{app\_id, label\_id}
\item events: \textit{event\_id, device\_id, timestamp, coordinates}
\item gender\_age: \textit{device\_id, gender, age, group}
\item phone\_brand\_device\_model: \textit{device\_id, phone\_brand, device\_model}
\end{itemize}

\subsection{Problem Description}
\textit{"Nothing is more comforting than being greeted by your favorite drink just as you walk through the door of the corner café." -- TalkingData Competition Page } 
\smallskip
\newline
\noindent
The goal of the competition is to predict mobile behaviour based upon app usage, phone brand and location information. As an abstraction upon this, the goal is to accurately predict in which gender and age group the owner of a mobile device resides. The predictions are accepted as twelve categories: six age groups for each gender. 
\subsection{Evaluation}
Submissions are evaluated using the multi-class logarithmic loss algorithm. For each device the output is a row in a csv file with the device\_id followed by twelve probabilities between 0 and 1 corresponding to the prediction for each class.
\section{Approach}
The following section discusses the approach to this problem. 
\subsection{Pre-Processing}
The pre-processing step was the most tedious phase. After merging the .csv files together the data was still incredibly sparse: over 80\% of the devices had missing data and over 2/3rds of all devices had no events linked to them. With that knowledge the data files were instead combined on basis of the device properties and the installed applications. 
\subsection{Feature Extraction}
The feature extraction was the same as the pre-processing as this was done in two different methods. 

The manual method was done by creating a co-occurrence matrix of each possible combination of features and the age gender group, gender and age. These matrices were made into histograms to visualize possible preferences of features per age gender group. These features were: Brand, Model, Apps installed and the amount of events present.

The automatic method consisted of One Hot Encoding all the features that were mentioned in the manual method, excluding events present. These One Hot Encoding arrays were then converted into a sparse matrix and were then dumped into pickle files. Which could be used for the pipeline. 

\subsection{Classifiers}
\subsubsection{Random Forests}
\subsubsection{XGBoost}
\subsubsection{Deep Learning/Neural networks}

In our project, we also tried to train and test a deep neural network. We used Keras, which is a Deep Learning library for Theano and Tensorflow. The implementation of Keras models is pretty straightforward: you create a model and add layers to it via already implemented methods. In the model, we used three different layers. The first is the Dense layer, which is just a normal densely-connected neural network layer, where you have to define how many neural units you want to use. Another layer we used was the Dropout layer. This layer sets a given fraction of inputs to zero, to compensate for overfitting. The third layer we used was PReLU, or Parametric Rectified Linear Unit, which `adaptively learns the parameters of the rectifiers, and improves accuracy at negligible extra computational cost.' \cite{PReLU}

After testing the model with some input data, we implemented the model into the pipeline. The variables that can be defined for testing are the number of iterations (splits for cross-validation) and the number of epochs (separately for the initial training cycles and the final training). Furthermore, you can change the Dropout rates and Dense units, but we tried to keep these constant by using commonly used values and values that returned better results.

\section{Results}
\section{XGBoost Results}
For the Kaggle submissions, both a linear model and the tree structure were used to test which resulted in a better score.

XGBoost Linear Model:
\begin{enumerate}
    \item Score: 2.26853
    \item Position: 776
\end{enumerate}

XGBoost Tree Model:
\begin{enumerate}
     \item Score: 2.27968
    \item Position: 996   
\end{enumerate}
\section{Discussion}
<discussie resultaten>
\section{Other ideas}
A number of concepts were considered but not explored. For features the many options with the spatial coordinates were not fully used. It could have been possible to reverse geocode the coordinate pairs to trace devices to cities and use that information as a feature. Additionally, many more features could have been involved that involve distance, density or time. 

\section{Individual Contributions}
By alphanummeric ordering:
\begin{itemize}
\item Jordi Beernink: \textit{Project leader, Pre-processing, XGBoost implementation}
\item Roel Bouman: \textit{Classification Pipeline and RF implementation}
\item Jeffrey Luppes: \textit{XGBoost implementation, Report writing}
\item Gerdriaan Mulder: \textit{Pre-processing, installation on the lilo servers}
\item Thijs Werrij - \textit{Deep Learning}
\end{itemize}
\subsection{Github Repository}
All code accompanying this report may be retrieved from \url{https://github.com/RoelBouman/Classified/tree/first_competition} where it has been bundled as a release. The README on that page alsohas extensive material on how to run the code on the lilo.science.ru.nl servers where it has been prepared for a demo. 
\medskip


\bibliography{mybib}{}
\bibliographystyle{plain}
\begin{thebibliography}{9}

@article{PReLU,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on
               ImageNet Classification},
  journal   = {CoRR},
  volume    = {abs/1502.01852},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.01852},
  timestamp = {Mon, 02 Mar 2015 14:17:34 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/HeZR015},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


\bibitem{Chen Tianqi, 2015}
Chen Tianqi
\emph{: TalkingData - Linear Model on Apps and Labels},
https://www.quora.com/What-is-the-difference-between-the-R-gbm-gradient-boosting-machine-and-xgboost-extreme-gradient-boosting,
Quora,
15th September 2015.
  
\bibitem{Chen Tianqi, 2014}
Chen Tianqi
\emph{: Digital design and computer architecture},  
A Gentle Introduction to Gradient Boosting,
University of Washington,
22nd October 2014

\bibitem{Aarshay Jain, 2016}
Aarshay Jain. 
\emph{: Digital design and computer architecture},  
https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/
Complete Guide to Parameter Tuning in XGBoost (with codes in Python)
1st March 2016

\end{thebibliography}

\end{document}
