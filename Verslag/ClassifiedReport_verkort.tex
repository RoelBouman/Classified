\documentclass[runningheads,a4paper]{llncs}

\usepackage[utf8]{inputenc}

\usepackage{natbib}
\bibliographystyle{apalike}

\usepackage{amssymb}
\setcounter{tocdepth}{5}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage[T1]{fontenc} % Pour que les lettres accentu√©es soient reconnues

\usepackage{url}
\urldef{\mailsa}\path|{alfred.hofmann, ursula.barth, ingrid.haas, frank.holzwarth,|
\urldef{\mailsb}\path|anna.kramer, leonie.kunz, christine.reiss, nicole.sator,|
\urldef{\mailsc}\path|erika.siebert-cole, peter.strasser, lncs}@springer.com|    
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}

\mainmatter 

\title{Classified: TalkingData}

\titlerunning{Classified: TalkingData}

\author{\textit{Classified is Jordi Beernink, Thijs Werrij, Roel Bouman, Gerdriaan Mulder, and Jeffrey Luppes}}

\institute{Radboud University}

\authorrunning{Team Classified - TalkingData}

\tocauthor{{}}

\maketitle
\section{Introduction}
\noindent
This report details the work done on the TalkingData Competition data set by the Classified team. While the competition closed in September of 2016, the data set remained public and open to submissions though the leaderboard was frozen.

\subsubsection{Problem Description}
The goal of the competition is to predict mobile behaviour based upon app usage, phone brand and location information. As an abstraction upon this, the goal is to accurately predict in which gender and age group the owner of a mobile device resides. The predictions are accepted as twelve categories: six age groups for each gender. Submissions to the competition are evaluated and ranked using the multi-class logarithmic loss algorithm.
\subsubsection{Data set}
The data set is hosted on Kaggle and consists of eight csv files totalling 1.2 GB. In order to generate a single data set these files were merged based on the device ID, which generated a data set of 4.2 GB. This data was fairly sparse, as many devices only had a few associated events, while others ranged in the thousands. This was true also for the phone brand types with some phones appearing only a few times while others had quite the market share. 

\section{Approach}
\subsubsection{Pre-Processing}
The pre-processing step was the most tedious phase. After merging the .csv files together the data was still incredibly sparse: over 2/3rds of all devices had no events linked to them. Prediction priority was given to the device properties and the installed applications.
\subsubsection{Feature Extraction}
All features present in the data set were aggregated into feature vectors based on the age/gender group. Additionally, some features were created by looking at what day of the week certain something was used. Using a clever One-hot-encoding, sparse matrices, and the pickle library present in Python. 
\subsection{Classifiers}
Initially a single pipeline using Random Forests was created, before being extended with other classification algorithms. 
\subsubsection{Random Forests}
To establish a baseline for a Random Forest Classifier from the Scikit-learn package was implemented, as it was presumed that it could serve as a starting point for more complex models. After scoring even worse than the benchmark submission of each class having an equal percentage it was quickly made clear that the sparse nature of the data was something that worked against the trees.
\subsubsection{Logistic Regression}
Unexpectedly good performance came from the Logistic Regression classifier. The best working solver for the large sparse data set was Limited-memory BFGS. 
\subsubsection{XGBoost}
Extreme Gradiant Boosting~\cite{CT2015} was used to much better effect than Random Forests. While computational intense, and harder to implement well, it was well suited for the problem. \medskip
\subsubsection{Deep Learning/Neural networks}
With the use of Keras, a library for Theano and Tensorflow, a neural network model was made. The network consists of several dense layers, dropout layers, and layers that use Parametric Rectified Linear Unit (PReLU) \cite{PReLU}. 


\section{Results}
The results of the classifiers are displayed in the following table. 

\begin{center}
    \begin{tabular}{| c | c | c|}
    \hline 
    Classifier & Mult-class logloss &  Kaggle rank (private leaderboard)\\ \hline
    Benchmark submission & 2.48491 & 1557 \\ \hline
    Random Forests & 3.261 & 1667 \\ \hline
    XGBoost tree & 2.280 & 996 \\ \hline
    XGBoost Linear & 2.269 & 776 \\ \hline
    Logistic Regression & 2.265 & 666 \\ \hline
    Neural Network (Keras) & 2.251 & 645 \\ \hline
    \end{tabular}
\end{center}

\section{Discussion}
The neural network outperformed the other classifiers well, but the relative simple logistic regression model did come extremely close. This is still better than over 60\% of the submissions. 

\section{Other ideas}
The main vector for improvement seems to be the pre-processing and the selection of features because a large amount of work was already done with optimizing the pipeline without significantly impacting the score in a positive way.

A number of concepts were considered but not explored. A lot information could have come from mapping users to urban areas or specific cities. Additionally, many more features could have been involved that involve distance, density or time. It was not allowed to enrich the data with outside data.

\section{Individual Contributions}
By alphanummeric ordering:
\begin{itemize}
\item Jordi Beernink: \textit{Project leader, Pre-processing, XGBoost implementation}
\item Roel Bouman: \textit{Classification Pipeline and RF implementation}
\item Jeffrey Luppes: \textit{XGBoost implementation, Report writing}
\item Gerdriaan Mulder: \textit{Pre-processing, installation on the lilo servers}
\item Thijs Werrij - \textit{Deep Learning}
\end{itemize}
\subsection{Github Repository}
All code accompanying this report may be retrieved from \url{https://github.com/RoelBouman/Classified/tree/first_competition} where it has been bundled as a release. The README on that page alsohas extensive material on how to run the code on the lilo.science.ru.nl servers where it has been prepared for a demo. 

\bibliography{mybib}{}
\bibliographystyle{plain}
\begin{thebibliography}{9}

\bibitem{CT2015}
Chen Tianqi
\emph{: TalkingData - Linear Model on Apps and Labels},
https://www.quora.com/What-is-the-difference-between-the-R-gbm-gradient-boosting-machine-and-xgboost-extreme-gradient-boosting,
Quora,
15th September 2015.

\bibitem{PReLU}
Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun
\emph{: Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
http://arxiv.org/abs/1502.01852,
CoRR,
2nd March 2015.  

\end{thebibliography}

\end{document}